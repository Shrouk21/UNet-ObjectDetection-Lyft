{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":34686,"sourceType":"datasetVersion","datasetId":27201},{"sourceId":2565747,"sourceType":"datasetVersion","datasetId":1557385}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\n\nmask = Image.open('/kaggle/input/lyft-udacity-challenge/dataA/dataA/CameraSeg/02_00_140.png')\n\nimage = Image.open('/kaggle/input/lyft-udacity-challenge/dataA/dataA/CameraRGB/02_00_140.png')\nmask.mode\n# print(f\"Mask shape: {mask.shape}\")\nprint(f\"Unique pixel values: {np.unique(mask)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:41:28.242674Z","iopub.execute_input":"2025-04-20T14:41:28.243260Z","iopub.status.idle":"2025-04-20T14:41:28.283077Z","shell.execute_reply.started":"2025-04-20T14:41:28.243207Z","shell.execute_reply":"2025-04-20T14:41:28.282488Z"}},"outputs":[{"name":"stdout","text":"Unique pixel values: [ 0  1  2  3  5  6  7  8  9 10 12]\n","output_type":"stream"}],"execution_count":130},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\ntransform = A.Compose([\n            A.Resize(256, 256),\n            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n            ToTensorV2()\n        ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:39:39.447321Z","iopub.execute_input":"2025-04-20T14:39:39.447969Z","iopub.status.idle":"2025-04-20T14:39:39.454849Z","shell.execute_reply.started":"2025-04-20T14:39:39.447945Z","shell.execute_reply":"2025-04-20T14:39:39.454128Z"}},"outputs":[],"execution_count":119},{"cell_type":"code","source":"augmented =transform(image=np.array(image),mask=np.array(mask))\nmask = augmented['mask']    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:40:16.674908Z","iopub.execute_input":"2025-04-20T14:40:16.675183Z","iopub.status.idle":"2025-04-20T14:40:16.694110Z","shell.execute_reply.started":"2025-04-20T14:40:16.675162Z","shell.execute_reply":"2025-04-20T14:40:16.693578Z"}},"outputs":[],"execution_count":126},{"cell_type":"code","source":"mask.to(torch.long)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:40:36.747148Z","iopub.execute_input":"2025-04-20T14:40:36.747466Z","iopub.status.idle":"2025-04-20T14:40:36.755233Z","shell.execute_reply.started":"2025-04-20T14:40:36.747443Z","shell.execute_reply":"2025-04-20T14:40:36.754488Z"}},"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"tensor([[ 1,  1,  1,  ...,  0,  0,  0],\n        [ 1,  1,  1,  ...,  0,  0,  0],\n        [ 1,  1,  1,  ...,  0,  0,  0],\n        ...,\n        [10, 10, 10,  ..., 10, 10, 10],\n        [10, 10, 10,  ..., 10, 10, 10],\n        [10, 10, 10,  ..., 10, 10, 10]])"},"metadata":{}}],"execution_count":128},{"cell_type":"code","source":"mask = np.array(mask)  \nh, w, _ = mask.shape\nmask = mask.reshape(-1, 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:39:56.706454Z","iopub.execute_input":"2025-04-20T14:39:56.706741Z","iopub.status.idle":"2025-04-20T14:39:56.711737Z","shell.execute_reply.started":"2025-04-20T14:39:56.706708Z","shell.execute_reply":"2025-04-20T14:39:56.710628Z"}},"outputs":[],"execution_count":123},{"cell_type":"code","source":"# Map RGB values to class indices\nclass_indices = np.array([class_map.get(tuple(rgb), -1) for rgb in mask])\n        \nmask = class_indices.reshape(h, w)  # Reshape back to [H, W]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:40:01.992630Z","iopub.execute_input":"2025-04-20T14:40:01.993173Z","iopub.status.idle":"2025-04-20T14:40:04.713524Z","shell.execute_reply.started":"2025-04-20T14:40:01.993152Z","shell.execute_reply":"2025-04-20T14:40:04.712941Z"}},"outputs":[],"execution_count":124},{"cell_type":"code","source":"for rgb in mask:\n    print(rgb)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:32:03.513683Z","iopub.execute_input":"2025-04-20T14:32:03.513966Z","iopub.status.idle":"2025-04-20T14:32:03.518559Z","shell.execute_reply.started":"2025-04-20T14:32:03.513945Z","shell.execute_reply":"2025-04-20T14:32:03.517643Z"}},"outputs":[{"name":"stdout","text":"[1 0 0]\n","output_type":"stream"}],"execution_count":103},{"cell_type":"code","source":"tuple(rgb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:35:22.179772Z","iopub.execute_input":"2025-04-20T14:35:22.180065Z","iopub.status.idle":"2025-04-20T14:35:22.185107Z","shell.execute_reply.started":"2025-04-20T14:35:22.180044Z","shell.execute_reply":"2025-04-20T14:35:22.184321Z"}},"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"(1, 0, 0)"},"metadata":{}}],"execution_count":112},{"cell_type":"code","source":"meh = class_map.get(tuple(rgb))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:38:02.736090Z","iopub.execute_input":"2025-04-20T14:38:02.737058Z","iopub.status.idle":"2025-04-20T14:38:02.740859Z","shell.execute_reply.started":"2025-04-20T14:38:02.737024Z","shell.execute_reply":"2025-04-20T14:38:02.740091Z"}},"outputs":[],"execution_count":115},{"cell_type":"code","source":"meh","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:38:04.247098Z","iopub.execute_input":"2025-04-20T14:38:04.247460Z","iopub.status.idle":"2025-04-20T14:38:04.252420Z","shell.execute_reply.started":"2025-04-20T14:38:04.247438Z","shell.execute_reply":"2025-04-20T14:38:04.251557Z"}},"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}],"execution_count":116},{"cell_type":"code","source":"class_indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:38:16.990395Z","iopub.execute_input":"2025-04-20T14:38:16.990899Z","iopub.status.idle":"2025-04-20T14:38:16.996551Z","shell.execute_reply.started":"2025-04-20T14:38:16.990875Z","shell.execute_reply":"2025-04-20T14:38:16.995721Z"}},"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"array([[ 1,  1,  1, ...,  0,  0,  0],\n       [ 1,  1,  1, ...,  0,  0,  0],\n       [ 1,  1,  1, ...,  0,  0,  0],\n       ...,\n       [10, 10, 10, ..., 10, 10, 10],\n       [10, 10, 10, ..., 10, 10, 10],\n       [10, 10, 10, ..., 10, 10, 10]])"},"metadata":{}}],"execution_count":118},{"cell_type":"code","source":"class_map","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:37:58.151910Z","iopub.execute_input":"2025-04-20T14:37:58.152187Z","iopub.status.idle":"2025-04-20T14:37:58.157579Z","shell.execute_reply.started":"2025-04-20T14:37:58.152166Z","shell.execute_reply":"2025-04-20T14:37:58.156786Z"}},"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"{(0, 0, 0): 0,\n (1, 0, 0): 1,\n (2, 0, 0): 2,\n (3, 0, 0): 3,\n (4, 0, 0): 4,\n (5, 0, 0): 5,\n (6, 0, 0): 6,\n (7, 0, 0): 7,\n (8, 0, 0): 8,\n (9, 0, 0): 9,\n (10, 0, 0): 10,\n (11, 0, 0): 11,\n (12, 0, 0): 12}"},"metadata":{}}],"execution_count":114},{"cell_type":"code","source":"mask[mask==-1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:07:01.840060Z","iopub.execute_input":"2025-04-20T14:07:01.840422Z","iopub.status.idle":"2025-04-20T14:07:01.848197Z","shell.execute_reply.started":"2025-04-20T14:07:01.840400Z","shell.execute_reply":"2025-04-20T14:07:01.847504Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"tensor([], dtype=torch.int32)"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"class_map = {(i,0,0):i for i in range(13)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:37:55.511176Z","iopub.execute_input":"2025-04-20T14:37:55.511985Z","iopub.status.idle":"2025-04-20T14:37:55.515784Z","shell.execute_reply.started":"2025-04-20T14:37:55.511960Z","shell.execute_reply":"2025-04-20T14:37:55.514975Z"}},"outputs":[],"execution_count":113},{"cell_type":"code","source":"isinstance(class_map, dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:34:43.078994Z","iopub.execute_input":"2025-04-20T14:34:43.079319Z","iopub.status.idle":"2025-04-20T14:34:43.084386Z","shell.execute_reply.started":"2025-04-20T14:34:43.079297Z","shell.execute_reply":"2025-04-20T14:34:43.083577Z"}},"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":111},{"cell_type":"code","source":"#mapping pixel to classes\n#create csv to store image and mask paths\nimport os\nimport numpy as np\ndef class_mapping(mask_dir):\n    unique_values=set()\n    for mask_subpath in os.listdir(mask_dir):\n        mask_path = os.path.join(mask_dir, mask_subpath)\n        mask = Image.open(mask_path)\n        mask = np.array(mask).reshape(-1, 3)\n        unique_values.update(map(tuple, mask))\n\n    return sorted(unique_values, key=lambda x: (x[0], x[1], x[2]))\n        \n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mask_dir='/kaggle/input/lyft-udacity-challenge/dataA/dataA/CameraSeg'\nclasses=class_mapping(mask_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_map = {tuple(rgb): idx for idx, rgb in enumerate(classes)}\nclass_map","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_map = {(i, 0, 0): i for i in range(13)}\nprint(class_map)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\ntorch.cuda.ipc_collect()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -rf /kaggle/working/UNet-SUIM\n\n%cd /kaggle/working\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:38:23.476236Z","iopub.execute_input":"2025-04-20T12:38:23.476475Z","iopub.status.idle":"2025-04-20T12:38:23.622406Z","shell.execute_reply.started":"2025-04-20T12:38:23.476456Z","shell.execute_reply":"2025-04-20T12:38:23.621091Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# !git init\n!git clone https://github.com/Shrouk21/UNet-SUIM.git\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:38:23.623631Z","iopub.execute_input":"2025-04-20T12:38:23.623956Z","iopub.status.idle":"2025-04-20T12:38:38.801308Z","shell.execute_reply.started":"2025-04-20T12:38:23.623922Z","shell.execute_reply":"2025-04-20T12:38:38.800358Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'UNet-SUIM'...\nremote: Enumerating objects: 186, done.\u001b[K\nremote: Counting objects: 100% (24/24), done.\u001b[K\nremote: Compressing objects: 100% (24/24), done.\u001b[K\nremote: Total 186 (delta 13), reused 0 (delta 0), pack-reused 162 (from 1)\u001b[K\nReceiving objects: 100% (186/186), 1.60 MiB | 114.00 KiB/s, done.\nResolving deltas: 100% (108/108), done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nos.chdir(\"/kaggle/working/UNet-SUIM\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:38:38.802475Z","iopub.execute_input":"2025-04-20T12:38:38.802713Z","iopub.status.idle":"2025-04-20T12:38:38.806865Z","shell.execute_reply.started":"2025-04-20T12:38:38.802691Z","shell.execute_reply":"2025-04-20T12:38:38.806052Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nprint(os.getcwd())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:38:44.338259Z","iopub.execute_input":"2025-04-20T12:38:44.338645Z","iopub.status.idle":"2025-04-20T12:38:44.342846Z","shell.execute_reply.started":"2025-04-20T12:38:44.338625Z","shell.execute_reply":"2025-04-20T12:38:44.342249Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/UNet-SUIM\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom PIL import Image\n# from dataloader import ImageDataModule\nfrom model import UNet\nfrom torchsummary import summary\nfrom datas import Dataloader\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom tensorboard.backend.event_processing.event_accumulator import EventAccumulator\nimport matplotlib.pyplot as plt\nimport os\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:38:44.344504Z","iopub.execute_input":"2025-04-20T12:38:44.344694Z","iopub.status.idle":"2025-04-20T12:38:44.355725Z","shell.execute_reply.started":"2025-04-20T12:38:44.344678Z","shell.execute_reply":"2025-04-20T12:38:44.355134Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def main():\n    # Set random seed for reproducibility\n    torch.manual_seed(0)\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(DEVICE.type)\n    # Define hyperparameters\n    n_filters = 32\n    batch_size = 16\n    input_shape = (batch_size, 3, 512, 512)  # Batch_size x Channels x Height x Width\n    num_workers = 4\n    val_split = 0.2\n    test_split = 0.1\n    epochs = 10\n    class_map = {(i, 0, 0): i for i in range(13)}\n    n_classes = len(class_map)\n\n    # Initialize the Dataloader\n    data_dir = '/kaggle/input/lyft-udacity-challenge/dataA/dataA'\n    dm = Dataloader(\n        data_dir=data_dir,\n        class_map=class_map,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        val_split=val_split,\n        test_split=test_split\n    )\n    # Setup the datasets\n    dm.setup()\n\n    # Initialize the LightningModule\n    model = UNet(input_shape[1], n_filters= n_filters, n_classes= n_classes)\n    model.to(DEVICE)\n    #print model summary\n    summary(model, input_shape[1:])\n\n    #Initialize the logger\n    logger = TensorBoardLogger(\"/kaggle/working/UNet-SUIM/lightning_logs\", name=None, version=0)\n\n    # Load the best checkpoint\n    checkpoint = ModelCheckpoint(monitor=\"val_loss\", save_top_k=1,  mode=\"min\")\n    filename=\"best_model-{epoch:02d}-{val_loss:.2f}\"\n    trainer = pl.Trainer(callbacks=[checkpoint], max_epochs=epochs, accelerator='cuda', devices=1)\n    trainer.fit(model, dm)\n\n    # Plot the loss and save it in the plots folder\n    log_dir = logger.log_dir\n    event_acc = EventAccumulator(log_dir)\n    event_acc.Reload()\n\n    # Extract loss and accuracy\n    train_loss = event_acc.Scalars(\"train_loss\")\n    val_loss = event_acc.Scalars(\"val_loss\")\n\n    # Create plots folder if it doesn't exist\n    os.makedirs(\"plots\", exist_ok=True)\n\n    # Plot Loss\n    plt.figure(figsize=(10, 5))\n    plt.plot([x.step for x in train_loss], [x.value for x in train_loss], label=\"Train Loss\", color=\"blue\")\n    plt.plot([x.step for x in val_loss], [x.value for x in val_loss], label=\"Validation Loss\", color=\"red\")\n    plt.xlabel(\"Step\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.title(\"Loss Curve\")\n    plt.savefig(\"plots/loss_curve.png\")\n    plt.close()\n\n\n# if __name__ == \"__main__\":\n#     main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:12:02.756179Z","iopub.execute_input":"2025-04-20T14:12:02.756472Z","iopub.status.idle":"2025-04-20T14:12:02.764977Z","shell.execute_reply.started":"2025-04-20T14:12:02.756453Z","shell.execute_reply":"2025-04-20T14:12:02.764336Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"main()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:12:05.182084Z","iopub.execute_input":"2025-04-20T14:12:05.182779Z","iopub.status.idle":"2025-04-20T14:12:05.284025Z","shell.execute_reply.started":"2025-04-20T14:12:05.182756Z","shell.execute_reply":"2025-04-20T14:12:05.283233Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_1569/1492567357.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  best_model.load_state_dict(torch.load(best_model_path)[\"state_dict\"])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1569/2019709742.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_1569/1492567357.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_filters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: ''","output_type":"error"}],"execution_count":52},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:10:07.649316Z","iopub.execute_input":"2025-04-20T14:10:07.649593Z","iopub.status.idle":"2025-04-20T14:10:07.672832Z","shell.execute_reply.started":"2025-04-20T14:10:07.649574Z","shell.execute_reply":"2025-04-20T14:10:07.671995Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1569/642819609.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use the best model checkpoint for predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_filters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'checkpoint' is not defined"],"ename":"NameError","evalue":"name 'checkpoint' is not defined","output_type":"error"}],"execution_count":46},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())\nprint(torch.cuda.get_device_name(0))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torchvision.transforms import transforms\nimport matplotlib.pyplot as plt\n\n# Define class map and number of classes\nclass_map = {(i, 0, 0): i for i in range(13)}\nn_classes = len(class_map)\nn_filters = 32\nbatch_size = 1\ninput_shape = (batch_size, 3, 512, 512)  # Batch_size x Channels x Height x Width\n# Initialize the Dataloader\ndata_dir = '/kaggle/input/lyft-udacity-challenge/dataA/dataA'\ndm = Dataloader(\n    data_dir=data_dir,\n    class_map=class_map,\n    batch_size=1,          # Use batch size of 1 for debugging\n    num_workers=4,\n    val_split=0.2,\n    test_split=0.1\n)\n\n# Setup the datasets\ndm.setup()\n\n# Access the training dataloader\ntest_loader = dm.test_dataloader()\n\n# Step 3: Get a single batch of data\nfor batch in test_loader:\n    x, y = batch  # x: input images, y: ground truth masks\n    break  # Stop after the first batch\nmodel = UNet(input_shape[1], n_filters= n_filters, n_classes= n_classes)\n# Step 4: Pass the batch through the model\nmodel.eval()  # Set the model to evaluation mode\nwith torch.no_grad():  # Disable gradient computation\n    preds = model(x)  # Forward pass\n\n# Step 5: Inspect the output\nprint(\"Input shape:\", x.shape)           # Should be [batch_size, C, H, W]\nprint(\"Prediction shape:\", preds.shape)  # Should be [batch_size, num_classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:17:07.283690Z","iopub.execute_input":"2025-04-20T14:17:07.284258Z","iopub.status.idle":"2025-04-20T14:17:10.676831Z","shell.execute_reply.started":"2025-04-20T14:17:07.284207Z","shell.execute_reply":"2025-04-20T14:17:10.675854Z"}},"outputs":[{"name":"stdout","text":"Looking for training images in: /kaggle/input/lyft-udacity-challenge/dataA/dataA/CameraSeg\nLooking for training masks in: /kaggle/input/lyft-udacity-challenge/dataA/dataA/CameraRGB\nInput shape: torch.Size([1, 3, 256, 256])\nPrediction shape: torch.Size([1, 13, 256, 256])\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"!git status","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:45:01.708608Z","iopub.execute_input":"2025-04-20T14:45:01.709453Z","iopub.status.idle":"2025-04-20T14:45:01.893111Z","shell.execute_reply.started":"2025-04-20T14:45:01.709406Z","shell.execute_reply":"2025-04-20T14:45:01.892438Z"}},"outputs":[{"name":"stdout","text":"On branch main\nYour branch is up to date with 'origin/main'.\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\t\u001b[31m__pycache__/datas.cpython-311.pyc\u001b[m\n\t\u001b[31m__pycache__/decoder.cpython-311.pyc\u001b[m\n\t\u001b[31m__pycache__/encoder.cpython-311.pyc\u001b[m\n\t\u001b[31m__pycache__/model.cpython-311.pyc\u001b[m\n\t\u001b[31mlightning_logs/\u001b[m\n\t\u001b[31mplots/\u001b[m\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n","output_type":"stream"}],"execution_count":134},{"cell_type":"code","source":"!git add .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:45:39.877367Z","iopub.execute_input":"2025-04-20T14:45:39.877661Z","iopub.status.idle":"2025-04-20T14:45:44.973705Z","shell.execute_reply.started":"2025-04-20T14:45:39.877638Z","shell.execute_reply":"2025-04-20T14:45:44.972762Z"}},"outputs":[],"execution_count":136},{"cell_type":"code","source":"!git commit -m 'logs and plots'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:46:50.086413Z","iopub.execute_input":"2025-04-20T14:46:50.087070Z","iopub.status.idle":"2025-04-20T14:46:50.265502Z","shell.execute_reply.started":"2025-04-20T14:46:50.087043Z","shell.execute_reply":"2025-04-20T14:46:50.264746Z"}},"outputs":[{"name":"stdout","text":"[main 85955a1] logs and plots\n 8 files changed, 4 insertions(+)\n create mode 100644 __pycache__/datas.cpython-311.pyc\n create mode 100644 __pycache__/decoder.cpython-311.pyc\n create mode 100644 __pycache__/encoder.cpython-311.pyc\n create mode 100644 __pycache__/model.cpython-311.pyc\n create mode 100644 lightning_logs/version_0/checkpoints/epoch=8-step=396.ckpt\n create mode 100644 lightning_logs/version_0/events.out.tfevents.1745152728.681eca032a7a.1569.0\n create mode 100644 lightning_logs/version_0/hparams.yaml\n create mode 100644 plots/loss_curve.png\n","output_type":"stream"}],"execution_count":141},{"cell_type":"code","source":"!git config user.email shrookkasem123@gmail.com\n!git config user.name Shrouk21","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:46:46.900189Z","iopub.execute_input":"2025-04-20T14:46:46.900870Z","iopub.status.idle":"2025-04-20T14:46:47.235452Z","shell.execute_reply.started":"2025-04-20T14:46:46.900841Z","shell.execute_reply":"2025-04-20T14:46:47.234609Z"}},"outputs":[],"execution_count":140},{"cell_type":"code","source":"!git push origin main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:47:02.096713Z","iopub.execute_input":"2025-04-20T14:47:02.097020Z"}},"outputs":[{"name":"stdout","text":"Username for 'https://github.com': ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}